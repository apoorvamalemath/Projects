Sentiment Analysis on Movie Review

CS 6120: Natural Language Processing - Fall 2022

Problem Statement: 
Classify the Movie Reviews as Negative, Somewhat negative, Neutral, Somewhat Positive, Positve.

Data Set: Rotten Tomato Dataset - https://www.kaggle.com/competitions/sentiment-analysis-on-movie-reviews/data

Data Description:
The dataset comprises of the following attributes:
PhraseId: Unique ID for each phrase
SentenceId: Unique ID assigned to each sentence 
Phrase: Subring selected from the review
Sentiment: Associated sentiment label 
The project code consists of the following modules:

The piples in the project encapsulate the following techniques:

1) Encoding techniques:
- TF-IDF
- Word2Vec - CBOW
- Word2Vec - SkipGram 
- Glove Embedding 
- Stemming/ Lemmatization and tokeniztion
- Sentence-T5 Transformer based Encoder
- BERT Encoder
  
2) Models:
We provide the functions to fit the following models:
- Logistic Regression with L2 Regularisation
- Random Forest Classifer with Grid Search
- Multinomial Naive Bayes with Grid Search
- Fully Connected Neural Networks
- LSTMs
- Bidirectional LSTMs
- BERT 

3) Metrics:
Defines function to calculate evaluation metrics - Accuracy, F1-Score, Precision and Re-call.
 

Steps to run the code:
-> Download the data and place it in the same folder as the code from the below mentioned dataset link:
https://www.kaggle.com/competitions/sentiment-analysis-on-movie-reviews/data
-> Each individual pipeline can be run seperately by running the respective notebooks sequentially.
-> 1_Understanding_the_data_EDA.ipynb oulines the distribution of the data.
-> 2_Embeddings_ML_models.ipynb can be run locally by installing the NLTK library. 
-> 3_Transformer_based_encoding_NN_LSTM_ML_models.ipynb requires GPU, and can be run on Kaggle notebooks or Google co-lab.
   - The installation of the transformer based encoder and downloading the pre-trained model is done within the notebook.
-> 4_BERT_transformer.ipynb requires GPU, and can be run on Kaggle notebooks or Google co-lab.
    - The installation of BERT encoder and downloading the pre-trained BERT is done within the notebook.
-> 5_Glove_LSTM.ipynb requires GPU, and can be run on Kaggle notebooks or Google co-lab.
    - Kindly provide the Glove embeddibng text file. 
-> 6_Stemming_Lemmetization_LSTM.ipynb requires GPU, and can be run on Kaggle notebooks or Google co-lab.
