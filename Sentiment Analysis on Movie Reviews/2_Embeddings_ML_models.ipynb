{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e76ca46",
   "metadata": {},
   "source": [
    "The pipeline has been built to fit ML models. We first apply data cleaning i.e. removal of links, punctuations, numbers, stop words, we then further convert the text to lower case and apply stemming. Stemming reduces the inflectional forms of each word into a common base word or root word or stem word. Inflection is a process of word formation, in which a word is modified to express different grammatical categories such as tense, case, voice, aspect, person, number, gender, mood, animacy, and definiteness.\n",
    "\n",
    "We then apply multiple embedding techniques like TF-IDF, and two implementations of word2vec i.e. Continuous Bag of Words (CBOW) and Skip Gram. We then use a simple ML model i.e. Logistic Regression and compare its performance with ensemble method like Random Forest Classifier and Multinomial Naive Bayes. We also apply grid search to find the optimum parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2e8d19fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c6735e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing the data\n",
    "train = pd.read_csv('train.tsv', sep='\\t')\n",
    "x = train['Phrase']\n",
    "y = train['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "091bc2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124848"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b58d99b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31212"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3509d3",
   "metadata": {},
   "source": [
    "# Preprocessing Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f604b645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TASK CELL\n",
    "en_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def clean_review(review):\n",
    "    '''\n",
    "    Input:\n",
    "        review: a string containing a review.\n",
    "    Output:\n",
    "        review_cleaned: a processed review. \n",
    "    '''\n",
    "    #Removing links\n",
    "    review_cleaned = re.sub(r'http\\S+', '', review)\n",
    "    \n",
    "    #Removing punctuations\n",
    "    table = str.maketrans(dict.fromkeys(string.punctuation)) \n",
    "    review_cleaned = review_cleaned.translate(table)   \n",
    "    \n",
    "    #Removing HTML Tags\n",
    "    review_cleaned = BeautifulSoup(review_cleaned).get_text()\n",
    "    \n",
    "    #Converting to lower case\n",
    "    review_cleaned = review_cleaned.lower()\n",
    "    \n",
    "    #Removing extra Spaces\n",
    "    review_cleaned = re.sub(\"\\s\\s+\", \" \", review_cleaned)\n",
    "    \n",
    "    #Removing numbers \n",
    "    review_cleaned = ''.join([i for i in review_cleaned if not i.isdigit()])\n",
    "    \n",
    "    #Removing stop words\n",
    "    review_cleaned = [w for w in re.split(\"\\W+\", review_cleaned) if not w in en_stopwords]\n",
    "    \n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    for i in range(len(review_cleaned)):\n",
    "        review_cleaned[i] = ps.stem(review_cleaned[i])\n",
    "  \n",
    "    temp = ' '.join(review_cleaned)\n",
    "    review_cleaned = re.sub('[^A-Za-z0-9.]+', ' ', temp)\n",
    "\n",
    "    return review_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d48eb6",
   "metadata": {},
   "source": [
    "# Text Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbe609",
   "metadata": {},
   "source": [
    "### 1. TF-IDF Vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b752cd6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def tf_idf(X_train, X_test):\n",
    "    vectorizer = TfidfVectorizer(max_features=3000)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.fit_transform(X_test)\n",
    "    return X_train_tfidf, X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b941f3",
   "metadata": {},
   "source": [
    "### 2. Word2Vec - CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d0cad931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "def word2vec_cbow(X_train, X_test, vector_size, window):\n",
    "    # Create CBOW model\n",
    "    X_train_cleaned = X_train.apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "    X_test_cleaned = X_test.apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "    w2v_model = gensim.models.Word2Vec(X_train_cleaned,\n",
    "                                   vector_size=vector_size,\n",
    "                                   window=window,\n",
    "                                   min_count=1)\n",
    "    # Generate aggregated sentence vectors based on the word vectors for each word in the sentence\n",
    "    # Replace the words in each text message with the learned word vector\n",
    "\n",
    "    words = set(w2v_model.wv.index_to_key )\n",
    "    X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                             for ls in X_train])\n",
    "    X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                             for ls in X_test])\n",
    "    \n",
    "    # Average the word vectors for each sentence (and assign a vector of zeros if the model\n",
    "    # did not learn any of the words in the text message during training\n",
    "    X_train_vect_avg = []\n",
    "    for v in X_train_vect:\n",
    "        if v.size:\n",
    "            X_train_vect_avg.append(v.mean(axis=0))\n",
    "        else:\n",
    "            X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
    "\n",
    "    X_test_vect_avg = []\n",
    "    for v in X_test_vect:\n",
    "        if v.size:\n",
    "            X_test_vect_avg.append(v.mean(axis=0))\n",
    "        else:\n",
    "            X_test_vect_avg.append(np.zeros(100, dtype=float))\n",
    "\n",
    "    return X_train_vect_avg, X_test_vect_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77fdde1",
   "metadata": {},
   "source": [
    "### 3. Word2Vec - Skip Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a5269589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "def word2vec_skip_gram(X_train, X_test, vector_size, window):\n",
    "    # Create CBOW model\n",
    "    #     X_train_cbow = gensim.models.Word2Vec(X_train, min_count = 1,\n",
    "    #                                   vector_size = 100, window = 5)\n",
    "    X_train_cleaned = X_train.apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "    X_test_cleaned = X_test.apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "    w2v_model = gensim.models.Word2Vec(X_train_cleaned,\n",
    "                                   vector_size = vector_size,\n",
    "                                   window = window,\n",
    "                                   min_count=1, \n",
    "                                   sg = 1)\n",
    "    # Generate aggregated sentence vectors based on the word vectors for each word in the sentence\n",
    "    # Replace the words in each text message with the learned word vector\n",
    "\n",
    "    words = set(w2v_model.wv.index_to_key )\n",
    "    X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                             for ls in X_train])\n",
    "    X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                             for ls in X_test])\n",
    "    \n",
    "    # Average the word vectors for each sentence (and assign a vector of zeros if the model\n",
    "    # did not learn any of the words in the text message during training\n",
    "    X_train_vect_avg = []\n",
    "    for v in X_train_vect:\n",
    "        if v.size:\n",
    "            X_train_vect_avg.append(v.mean(axis=0))\n",
    "        else:\n",
    "            X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
    "\n",
    "    X_test_vect_avg = []\n",
    "    for v in X_test_vect:\n",
    "        if v.size:\n",
    "            X_test_vect_avg.append(v.mean(axis=0))\n",
    "        else:\n",
    "            X_test_vect_avg.append(np.zeros(100, dtype=float))\n",
    "\n",
    "    return X_train_vect_avg, X_test_vect_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d160d",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1931ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(y_test, y_pred):\n",
    "    result = {}\n",
    "    result['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    result['Precision_weighted'] = precision_score(y_test, y_pred, average='weighted')\n",
    "    result['Recall_weighted'] = recall_score(y_test, y_pred, average='weighted')\n",
    "    result['F1 Score_weighted'] = f1_score(y_test, y_pred, average='weighted')\n",
    "    result['Precision_micro'] = precision_score(y_test, y_pred, average='micro')\n",
    "    result['Recall_micro'] = recall_score(y_test, y_pred, average='micro')\n",
    "    result['F1 Score_micro'] = f1_score(y_test, y_pred, average='micro')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "614db855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = X_train.apply(clean_review)\n",
    "X_test_cleaned = X_test.apply(clean_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6a094",
   "metadata": {},
   "source": [
    "### 1. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b4cda1",
   "metadata": {},
   "source": [
    "#### TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "996c1db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.44743689320388347,\n",
       " 'Precision_weighted': 0.36651705448180216,\n",
       " 'Recall_weighted': 0.44743689320388347,\n",
       " 'F1 Score_weighted': 0.3936339766686303,\n",
       " 'Precision_micro': 0.44743689320388347,\n",
       " 'Recall_micro': 0.44743689320388347,\n",
       " 'F1 Score_micro': 0.44743689320388347}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train_encoded, X_test_encoded = tf_idf(X_train_cleaned, X_test_cleaned)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_encoded, y_train)\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "\n",
    "res = evaluation_metrics(y_test, y_pred)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c22c97d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.01      0.02      2319\n",
      "           1       0.19      0.12      0.15      9054\n",
      "           2       0.54      0.76      0.63     26226\n",
      "           3       0.25      0.18      0.21     10886\n",
      "           4       0.04      0.01      0.01      3015\n",
      "\n",
      "    accuracy                           0.45     51500\n",
      "   macro avg       0.21      0.22      0.20     51500\n",
      "weighted avg       0.37      0.45      0.39     51500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3a70a",
   "metadata": {},
   "source": [
    "#### Word2Vec - CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f8714da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== vector size: 100  window:  2  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n",
      "===== vector size: 100  window:  5  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "vector_size = [100, 100]\n",
    "window = [2, 5]\n",
    "for i in range(len(window)):\n",
    "    print(\"===== vector size:\", vector_size[i], \" window: \", window[i],\" ======\")\n",
    "    X_train_encoded, X_test_encoded = word2vec_cbow(X_train_cleaned, X_test_cleaned, \n",
    "                                                    vector_size[i], window[i])\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    \n",
    "    res = evaluation_metrics(y_test, y_pred)\n",
    "    print(res)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3de59",
   "metadata": {},
   "source": [
    "#### Word2Vec - Skip Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38052e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== vector size: 100  window:  2  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n",
      "===== vector size: 100  window:  5  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "vector_size = [100, 100]\n",
    "window = [2, 5]\n",
    "for i in range(len(window)):\n",
    "    print(\"===== vector size:\", vector_size[i], \" window: \", window[i],\" ======\")\n",
    "    X_train_encoded, X_test_encoded = word2vec_skip_gram(X_train_cleaned, X_test_cleaned, \n",
    "                                                    vector_size[i], window[i])\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    \n",
    "    res = evaluation_metrics(y_test, y_pred)\n",
    "    print(res)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8a7571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.509242718446602,\n",
       " 'Precision_weighted': 0.2593281462908851,\n",
       " 'Recall_weighted': 0.509242718446602,\n",
       " 'F1 Score_weighted': 0.3436533343792446,\n",
       " 'Precision_micro': 0.509242718446602,\n",
       " 'Recall_micro': 0.509242718446602,\n",
       " 'F1 Score_micro': 0.509242718446602}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search\n",
    "param_grid = { \n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [8, 16, 20, 25, 35],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train_encoded, y_train)\n",
    "print(CV_rfc.best_params_)\n",
    "y_pred = CV_rfc.predict(X_test_encoded)\n",
    "res = evaluation_metrics(y_test, y_pred)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c86eb348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7bdbd4",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf537fe",
   "metadata": {},
   "source": [
    "#### TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80d99ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.47067961165048544,\n",
       " 'Precision_weighted': 0.372624801562607,\n",
       " 'Recall_weighted': 0.47067961165048544,\n",
       " 'F1 Score_weighted': 0.4000572646465387,\n",
       " 'Precision_micro': 0.47067961165048544,\n",
       " 'Recall_micro': 0.47067961165048544,\n",
       " 'F1 Score_micro': 0.4706796116504855}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train_encoded, X_test_encoded = tf_idf(X_train_cleaned, X_test_cleaned)\n",
    "model = LogisticRegression(random_state=0).fit(X_train_encoded, y_train)\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "\n",
    "res = evaluation_metrics(y_test, y_pred)\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4d0dbf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd3141",
   "metadata": {},
   "source": [
    "#### Word2Vec - CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1c831815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== vector size: 100  window:  2  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n",
      "===== vector size: 100  window:  5  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_size = [100, 100]\n",
    "window = [2, 5]\n",
    "for i in range(len(window)):\n",
    "    print(\"===== vector size:\", vector_size[i], \" window: \", window[i],\" ======\")\n",
    "    X_train_encoded, X_test_encoded = word2vec_cbow(X_train_cleaned, X_test_cleaned, \n",
    "                                                    vector_size[i], window[i])\n",
    "    model = LogisticRegression(random_state=0)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    \n",
    "    res = evaluation_metrics(y_test, y_pred)\n",
    "    print(res)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39511db4",
   "metadata": {},
   "source": [
    "#### Word2Vec - Skip Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "06895894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== vector size: 100  window:  2  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n",
      "===== vector size: 100  window:  5  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_size = [100, 100]\n",
    "window = [2, 5]\n",
    "for i in range(len(window)):\n",
    "    print(\"===== vector size:\", vector_size[i], \" window: \", window[i],\" ======\")\n",
    "    X_train_encoded, X_test_encoded = word2vec_skip_gram(X_train_cleaned, X_test_cleaned, \n",
    "                                                    vector_size[i], window[i])\n",
    "    model = LogisticRegression(random_state=0)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    \n",
    "    res = evaluation_metrics(y_test, y_pred)\n",
    "    print(res)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da175f3",
   "metadata": {},
   "source": [
    "### 3. MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "425a2034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.4763495145631068, 'Precision_weighted': 0.35207242540890255, 'Recall_weighted': 0.4763495145631068, 'F1 Score_weighted': 0.37007545189467633, 'Precision_micro': 0.4763495145631068, 'Recall_micro': 0.4763495145631068, 'F1 Score_micro': 0.4763495145631068}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.00      0.00      2319\n",
      "           1       0.21      0.06      0.09      9054\n",
      "           2       0.51      0.88      0.65     26226\n",
      "           3       0.24      0.08      0.11     10886\n",
      "           4       0.06      0.00      0.01      3015\n",
      "\n",
      "    accuracy                           0.48     51500\n",
      "   macro avg       0.21      0.20      0.17     51500\n",
      "weighted avg       0.35      0.48      0.37     51500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train_encoded, X_test_encoded = tf_idf(X_train_cleaned, X_test_cleaned)\n",
    "model = MultinomialNB().fit(X_train_encoded, y_train)\n",
    "y_pred = model.predict(X_test_encoded)\n",
    "\n",
    "res = evaluation_metrics(y_test, y_pred)\n",
    "print(res)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eaa8aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== vector size: 100  window:  2  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n",
      "===== vector size: 100  window:  5  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_size = [100, 100]\n",
    "window = [2, 5]\n",
    "for i in range(len(window)):\n",
    "    print(\"===== vector size:\", vector_size[i], \" window: \", window[i],\" ======\")\n",
    "    X_train_encoded, X_test_encoded = word2vec_cbow(X_train_cleaned, X_test_cleaned, \n",
    "                                                    vector_size[i], window[i])\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    \n",
    "    res = evaluation_metrics(y_test, y_pred)\n",
    "    print(res)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e84daaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== vector size: 100  window:  2  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n",
      "===== vector size: 100  window:  5  ======\n",
      "{'Accuracy': 0.509242718446602, 'Precision_weighted': 0.2593281462908851, 'Recall_weighted': 0.509242718446602, 'F1 Score_weighted': 0.3436533343792446, 'Precision_micro': 0.509242718446602, 'Recall_micro': 0.509242718446602, 'F1 Score_micro': 0.509242718446602}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2319\n",
      "           1       0.00      0.00      0.00      9054\n",
      "           2       0.51      1.00      0.67     26226\n",
      "           3       0.00      0.00      0.00     10886\n",
      "           4       0.00      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.51     51500\n",
      "   macro avg       0.10      0.20      0.13     51500\n",
      "weighted avg       0.26      0.51      0.34     51500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_size = [100, 100]\n",
    "window = [2, 5]\n",
    "for i in range(len(window)):\n",
    "    print(\"===== vector size:\", vector_size[i], \" window: \", window[i],\" ======\")\n",
    "    X_train_encoded, X_test_encoded = word2vec_skip_gram(X_train_cleaned, X_test_cleaned, \n",
    "                                                    vector_size[i], window[i])\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    y_pred = model.predict(X_test_encoded)\n",
    "    \n",
    "    res = evaluation_metrics(y_test, y_pred)\n",
    "    print(res)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1715bde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.4713009708737864,\n",
       " 'Precision_weighted': 0.3499657625080404,\n",
       " 'Recall_weighted': 0.4713009708737864,\n",
       " 'F1 Score_weighted': 0.3701759177508324,\n",
       " 'Precision_micro': 0.4713009708737864,\n",
       " 'Recall_micro': 0.4713009708737864,\n",
       " 'F1 Score_micro': 0.4713009708737864}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_grid = { \n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "nb=MultinomialNB()\n",
    "\n",
    "CV_nb = GridSearchCV(estimator=nb, param_grid=param_grid, cv= 5)\n",
    "CV_nb.fit(X_train_encoded, y_train)\n",
    "print(CV_nb.best_params_)\n",
    "y_pred = CV_nb.predict(X_test_encoded)\n",
    "res = evaluation_metrics(y_test, y_pred)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ccee2068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.00      0.00      2319\n",
      "           1       0.20      0.06      0.09      9054\n",
      "           2       0.51      0.87      0.64     26226\n",
      "           3       0.24      0.08      0.12     10886\n",
      "           4       0.03      0.00      0.00      3015\n",
      "\n",
      "    accuracy                           0.47     51500\n",
      "   macro avg       0.21      0.20      0.17     51500\n",
      "weighted avg       0.35      0.47      0.37     51500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244b152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac80aee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
