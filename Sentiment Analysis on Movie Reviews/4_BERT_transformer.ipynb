{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a transformer based model i.e. Bidirectional Encoder Representations from Transformers (BERT). It is a type of language model that uses deep learning to generate contextual representations of words in a sentence. BERT was developed by researchers at Google and has been shown to be very effective at a wide range of natural language processing tasks, such as sentiment analysis, text summarization, and named entity recognition. \n",
    "\n",
    "One of the key features of BERT is that it is a \"bidirectional\" model, which means that it takes into account the context of a word in both the left and right sides of the sentence when generating its representation. This is in contrast to other language models, which only consider the context on one side of the sentence. This bidirectional approach allows BERT to capture a more nuanced and accurate representation of the meaning of words in a sentence, which makes it well-suited for many natural language processing tasks. It uses the \"Transformer\" architecture, which is a type of neural network that is particularly well-suited for processing sequential data such as text. The Transformer architecture allows BERT to efficiently process long sequences of words and to capture the relationships between words at different positions in the sentence. \n",
    "\n",
    "We use the BERT model with another hidden layer with 1024 neurons with Relu as the activation function and an output layer with 5 neurons with Softmax as the activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-09T02:13:03.477906Z",
     "iopub.status.busy": "2022-12-09T02:13:03.477560Z",
     "iopub.status.idle": "2022-12-09T02:13:03.520487Z",
     "shell.execute_reply": "2022-12-09T02:13:03.519696Z",
     "shell.execute_reply.started": "2022-12-09T02:13:03.477873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sentiment-analysis-on-movie-reviews/sampleSubmission.csv\n",
      "/kaggle/input/sentiment-analysis-on-movie-reviews/train.tsv.zip\n",
      "/kaggle/input/sentiment-analysis-on-movie-reviews/test.tsv.zip\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from transformers import TFBertModel,  BertConfig, BertTokenizerFast, TFAutoModel\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import zipfile\n",
    "import os\n",
    "with zipfile.ZipFile('/kaggle/input/sentiment-analysis-on-movie-reviews/train.tsv.zip','r') as zip_ref:\n",
    "    zip_ref.extractall(\"./sentiment-analysis-on-movie-reviews/\")\n",
    "with zipfile.ZipFile('/kaggle/input/sentiment-analysis-on-movie-reviews/test.tsv.zip','r') as zip_ref:\n",
    "    zip_ref.extractall(\"./sentiment-analysis-on-movie-reviews/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T02:13:04.321347Z",
     "iopub.status.busy": "2022-12-09T02:13:04.321002Z",
     "iopub.status.idle": "2022-12-09T02:13:04.440303Z",
     "shell.execute_reply": "2022-12-09T02:13:04.439432Z",
     "shell.execute_reply.started": "2022-12-09T02:13:04.321312Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import data\n",
    "data=pd.read_table(\"/kaggle/working/sentiment-analysis-on-movie-reviews/train.tsv\",sep='\\t')\n",
    "data=data[['Phrase','Sentiment']].copy()\n",
    "dff=[len(i.split(\" \")) for i in data.Phrase[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T02:13:07.100947Z",
     "iopub.status.busy": "2022-12-09T02:13:07.100662Z",
     "iopub.status.idle": "2022-12-09T02:13:07.136790Z",
     "shell.execute_reply": "2022-12-09T02:13:07.135979Z",
     "shell.execute_reply.started": "2022-12-09T02:13:07.100919Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data.index.values, \n",
    "                                                  data.Sentiment.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42)\n",
    "\n",
    "data['data_type'] = ['not_set']*data.shape[0]\n",
    "\n",
    "data.loc[X_train, 'data_type'] = 'train'\n",
    "data.loc[X_val, 'data_type'] = 'val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T02:13:07.181282Z",
     "iopub.status.busy": "2022-12-09T02:13:07.181022Z",
     "iopub.status.idle": "2022-12-09T02:13:09.981406Z",
     "shell.execute_reply": "2022-12-09T02:13:09.980538Z",
     "shell.execute_reply.started": "2022-12-09T02:13:07.181256Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'bert-base-cased'\n",
    "\n",
    "# Max length of tokens\n",
    "max_length = max(dff)+3\n",
    "\n",
    "# Load transformers config \n",
    "config = BertConfig.from_pretrained(model_name)\n",
    "config.output_hidden_states = False\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T02:13:09.983194Z",
     "iopub.status.busy": "2022-12-09T02:13:09.982852Z",
     "iopub.status.idle": "2022-12-09T02:13:13.195241Z",
     "shell.execute_reply": "2022-12-09T02:13:13.193747Z",
     "shell.execute_reply.started": "2022-12-09T02:13:09.983152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attention_mask (InputLayer)     [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids (InputLayer)          [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 108310272   attention_mask[0][0]             \n",
      "                                                                 input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         787456      bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            5125        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,102,853\n",
      "Trainable params: 109,102,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build your model input\n",
    "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
    "attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32') \n",
    "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "bert = TFAutoModel.from_pretrained('bert-base-cased')\n",
    "embeddings = bert.bert(inputs)[1]  # access pooled activations with [1]\n",
    "\n",
    "x =Dense(1024, activation='relu')(embeddings)\n",
    "y =Dense(5, activation='softmax', name='outputs')(x)\n",
    "model = Model(inputs=inputs, outputs=y)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T02:13:13.197334Z",
     "iopub.status.busy": "2022-12-09T02:13:13.196995Z",
     "iopub.status.idle": "2022-12-09T02:13:20.089095Z",
     "shell.execute_reply": "2022-12-09T02:13:20.088245Z",
     "shell.execute_reply.started": "2022-12-09T02:13:13.197296Z"
    }
   },
   "outputs": [],
   "source": [
    "y_senti = to_categorical(data[data.data_type=='train'].Sentiment)\n",
    "\n",
    "# Tokenize the input \n",
    "x = tokenizer(\n",
    "    text=data[data.data_type=='train'].Phrase.to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "train=tf.data.Dataset.from_tensor_slices((x['input_ids'], x['attention_mask'], y_senti))\n",
    "def map_func(input_ids, masks, labels):\n",
    "    # convert three-item tuple into a two-item tuple where the input item is a dictionary\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "\n",
    "train = train.map(map_func)\n",
    "batch_size = 32\n",
    "train = train.shuffle(100).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T02:13:20.100989Z",
     "iopub.status.busy": "2022-12-09T02:13:20.100589Z",
     "iopub.status.idle": "2022-12-09T02:13:21.363673Z",
     "shell.execute_reply": "2022-12-09T02:13:21.362835Z",
     "shell.execute_reply.started": "2022-12-09T02:13:20.100954Z"
    }
   },
   "outputs": [],
   "source": [
    "y_senti = to_categorical(data[data.data_type=='val'].Sentiment)\n",
    "\n",
    "# Tokenize the input \n",
    "x = tokenizer(\n",
    "    text=data[data.data_type=='val'].Phrase.to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "val = tf.data.Dataset.from_tensor_slices((x['input_ids'], x['attention_mask'], y_senti))\n",
    "val = val.map(map_func)\n",
    "val = val.shuffle(100).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T02:13:21.365667Z",
     "iopub.status.busy": "2022-12-09T02:13:21.365092Z",
     "iopub.status.idle": "2022-12-09T02:13:21.457493Z",
     "shell.execute_reply": "2022-12-09T02:13:21.456702Z",
     "shell.execute_reply.started": "2022-12-09T02:13:21.365616Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-5, decay=1e-6)\n",
    "loss = CategoricalCrossentropy()\n",
    "acc = CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T02:13:21.459002Z",
     "iopub.status.busy": "2022-12-09T02:13:21.458674Z",
     "iopub.status.idle": "2022-12-09T02:47:55.511503Z",
     "shell.execute_reply": "2022-12-09T02:47:55.510655Z",
     "shell.execute_reply.started": "2022-12-09T02:13:21.458966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4145/4145 [==============================] - 697s 166ms/step - loss: 0.8915 - accuracy: 0.6399 - val_loss: 0.7376 - val_accuracy: 0.6894\n",
      "Epoch 2/3\n",
      "4145/4145 [==============================] - 689s 166ms/step - loss: 0.6867 - accuracy: 0.7144 - val_loss: 0.7265 - val_accuracy: 0.6944\n",
      "Epoch 3/3\n",
      "4145/4145 [==============================] - 688s 166ms/step - loss: 0.6004 - accuracy: 0.7510 - val_loss: 0.7582 - val_accuracy: 0.6924\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T02:47:55.514690Z",
     "iopub.status.busy": "2022-12-09T02:47:55.514340Z",
     "iopub.status.idle": "2022-12-09T02:48:30.237103Z",
     "shell.execute_reply": "2022-12-09T02:48:30.236211Z",
     "shell.execute_reply.started": "2022-12-09T02:47:55.514653Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('./sentiment-analysis-on-movie-reviews/sentiment_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T03:11:23.222640Z",
     "iopub.status.busy": "2022-12-09T03:11:23.222296Z",
     "iopub.status.idle": "2022-12-09T03:11:23.235146Z",
     "shell.execute_reply": "2022-12-09T03:11:23.234271Z",
     "shell.execute_reply.started": "2022-12-09T03:11:23.222611Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data.index.values, \n",
    "                                                  data.Sentiment.values, \n",
    "                                                  test_size=0.20, \n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T03:11:24.231074Z",
     "iopub.status.busy": "2022-12-09T03:11:24.230749Z",
     "iopub.status.idle": "2022-12-09T03:11:24.243581Z",
     "shell.execute_reply": "2022-12-09T03:11:24.242638Z",
     "shell.execute_reply.started": "2022-12-09T03:11:24.231044Z"
    }
   },
   "outputs": [],
   "source": [
    "test = data.loc[X_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T03:11:25.096476Z",
     "iopub.status.busy": "2022-12-09T03:11:25.096113Z",
     "iopub.status.idle": "2022-12-09T03:11:26.665785Z",
     "shell.execute_reply": "2022-12-09T03:11:26.664874Z",
     "shell.execute_reply.started": "2022-12-09T03:11:25.096443Z"
    }
   },
   "outputs": [],
   "source": [
    "x = tokenizer(\n",
    "    text=test.Phrase.to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T03:11:31.695314Z",
     "iopub.status.busy": "2022-12-09T03:11:31.694960Z",
     "iopub.status.idle": "2022-12-09T03:11:31.700559Z",
     "shell.execute_reply": "2022-12-09T03:11:31.699412Z",
     "shell.execute_reply.started": "2022-12-09T03:11:31.695271Z"
    }
   },
   "outputs": [],
   "source": [
    "items=tf.data.Dataset.from_tensor_slices((x['input_ids'],x['attention_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T03:11:32.033605Z",
     "iopub.status.busy": "2022-12-09T03:11:32.033279Z",
     "iopub.status.idle": "2022-12-09T03:11:32.039780Z",
     "shell.execute_reply": "2022-12-09T03:11:32.038796Z",
     "shell.execute_reply.started": "2022-12-09T03:11:32.033576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((40,), (40,)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T03:11:33.267526Z",
     "iopub.status.busy": "2022-12-09T03:11:33.267146Z",
     "iopub.status.idle": "2022-12-09T03:11:33.279387Z",
     "shell.execute_reply": "2022-12-09T03:11:33.278558Z",
     "shell.execute_reply.started": "2022-12-09T03:11:33.267491Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks):\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}\n",
    "\n",
    "items = items.map(map_func)\n",
    "items = items.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T03:11:38.516150Z",
     "iopub.status.busy": "2022-12-09T03:11:38.515819Z",
     "iopub.status.idle": "2022-12-09T03:12:40.075132Z",
     "shell.execute_reply": "2022-12-09T03:12:40.074240Z",
     "shell.execute_reply.started": "2022-12-09T03:11:38.516118Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(items).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-09T03:12:40.078932Z",
     "iopub.status.busy": "2022-12-09T03:12:40.078678Z",
     "iopub.status.idle": "2022-12-09T03:12:40.129939Z",
     "shell.execute_reply": "2022-12-09T03:12:40.128775Z",
     "shell.execute_reply.started": "2022-12-09T03:12:40.078905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.53      0.55      1416\n",
      "           1       0.62      0.68      0.65      5527\n",
      "           2       0.81      0.81      0.81     15639\n",
      "           3       0.67      0.59      0.63      6707\n",
      "           4       0.55      0.68      0.61      1923\n",
      "\n",
      "    accuracy                           0.72     31212\n",
      "   macro avg       0.65      0.66      0.65     31212\n",
      "weighted avg       0.72      0.72      0.72     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_val,predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
