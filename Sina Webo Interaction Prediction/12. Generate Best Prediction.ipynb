{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluation.ipynb\n",
      "importing Jupyter notebook from runTime.ipynb\n"
     ]
    }
   ],
   "source": [
    "import _pickle as cPickle\n",
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from genUidStat import loadData,genUidStat\n",
    "from evaluation import precision\n",
    "from runTime import runTime\n",
    "from pathos.pools import _ProcessPool\n",
    "from multiprocess.pool import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"weibo_train1.csv\")\n",
    "df2=pd.read_csv(\"weibo_train2.csv\")\n",
    "frames=[df1,df2]\n",
    "traindata=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataFrameIntoSmaller(df, chunkSize = 10000): \n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])\n",
    "    return listOfDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_stat=pd.read_csv(\"train_uid_stat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = splitDataFrameIntoSmaller(uid_stat, chunkSize = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_all_uid(stat_dic,file):\n",
    "\timport pandas as pd\n",
    "\timport numpy as np\n",
    "\tdef _deviation(predict, real, kind):\n",
    "\t\tt = 5.0 if kind=='f' else 3.0\n",
    "\t\treturn abs(predict - real) / (real + t)\n",
    "\tdef _precision_i(fp, fr, cp, cr, lp, lr):\n",
    "\t\treturn 1 - 0.5 * _deviation(fp, fr, 'f') - 0.25 * _deviation(cp, cr, 'c') - 0.25 * _deviation(lp, lr, 'l')\n",
    "\tdef _sgn(x):\n",
    "\t\treturn 1 if x>0 else 0\n",
    "\tdef _count_i(fr, cr, lr):\n",
    "\t\tx = fr + cr + lr\n",
    "\t\treturn 101 if x>100 else (x+1)\n",
    "\tdef precision(real_and_predict):\n",
    "\t\tnumerator,denominator = 0.0,0.0\n",
    "\t\tfor  fr, cr, lr,fp, cp, lp in real_and_predict:\n",
    "\t\t\tnumerator += _count_i(fr, cr, lr) * _sgn(_precision_i(fp, fr, cp, cr, lp, lr) - 0.8)\n",
    "\t\t\tdenominator += _count_i(fr, cr, lr)\n",
    "\t\treturn (numerator / denominator)\n",
    "\tdef score(uid_data,pred):\n",
    "\t\t\"\"\"\n",
    "\t\tuid_data:\n",
    "\t\t\tpd.DataFrame\n",
    "\t\tpred:\n",
    "\t\t\tlist, [fp,cp,lp]\n",
    "\t\t\"\"\"\n",
    "\t\tuid_real_pred = uid_data[['forward_count','comment_count','like_count']]\n",
    "\t\tuid_real_pred['fp'] = pred[0]\n",
    "\t\tuid_real_pred['cp'] = pred[1]\n",
    "\t\tuid_real_pred['lp'] = pred[2]\n",
    "\t\treturn precision(uid_real_pred.values)\n",
    "\tdef search(uid_data,target,args):\n",
    "\t\targs = list(args)\n",
    "\t\ttarget_index = ['forward_count','comment_count','like_count'].index(target)\n",
    "\t\ttarget_min,target_median,target_max = args[3*target_index:3*target_index+3]\n",
    "\t\tdel args[3*target_index:3*target_index+3]\n",
    "\t\tpred = (args[1],args[4])\n",
    "\t\t\n",
    "\t\tbest_num = [target_median]\n",
    "\t\tbest_pred = list(pred)\n",
    "\t\tbest_pred.insert(target_index,target_median)\n",
    "\t\tbest_score = score(uid_data,best_pred)\n",
    "\t\tfor num in range(target_min,target_max+1):\n",
    "\t\t\tthis_pred = list(pred)\n",
    "\t\t\tthis_pred.insert(target_index,num)\n",
    "\t\t\tthis_score = score(uid_data,this_pred)\n",
    "\t\t\tif this_score >= best_score:                  \n",
    "\t\t\t\tif this_score > best_score:\n",
    "\t\t\t\t\tbest_num = [num]\n",
    "\t\t\t\t\tbest_score = this_score\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tbest_num.append(num)                       \n",
    "\t\t\t\t\n",
    "\t\treturn best_num[np.array([abs(i - target_median) for i in best_num]).argmin()]\n",
    "\tuid_best_pred = {}\n",
    "\tpool = _ProcessPool()\n",
    "\tuids,f,c,l = [],[],[],[]\n",
    "\tm=1\n",
    "\tfor uid in stat_dic:\n",
    "\t\tprint (\"search uid:{}\".format(uid),m)\n",
    "\t\tm=m+1\n",
    "\t\tuid_data = traindata[traindata.u_id == uid]\n",
    "\t\targuments = stat_dic[uid][['forward_min','forward_median','forward_max','comment_min',\\\n",
    "\t\t\t\t\t'comment_median','comment_max','like_min','like_median','like_max']]\n",
    "\t\targuments = tuple([int(i) for i in arguments]) \n",
    "\t\tf.append(pool.apply_async(search,args=(uid_data,'forward_count',arguments)))\n",
    "\t\tc.append(pool.apply_async(search,args=(uid_data,'comment_count',arguments)))\n",
    "\t\tl.append(pool.apply_async(search,args=(uid_data,'like_count',arguments)))\n",
    "\t\tuids.append(uid)\n",
    "\tpool.close()\n",
    "\tpool.join()\n",
    "\tf = [i.get() for i in f]\n",
    "\tc = [i.get() for i in c]\n",
    "\tl = [i.get() for i in l]\n",
    "\tfor i in range(len(uids)):\n",
    "\t\tuid_best_pred[uids[i]] = [f[i],c[i],l[i]]\n",
    "\t#cPickle.dump(uid_best_pred,open('uid_best_pred'+str(file)+'.pkl','ab'))\n",
    "\tlabel = ['forward_count','comment_count','like_count']\n",
    "\tpd.DataFrame.from_dict(data=uid_best_pred,orient='index').to_csv(\"G:\\\\Anconda Prog\\\\BestPred\\\\weibo_uidbest\"+str(file)+\".csv\",header=label)\n",
    "\tprint(\"Written to file\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search uid:059e69f515a8ccae9005d9184082e1a7 1\n",
      "search uid:059f1af2f4d0cc0c11f7c2333fb56df9 2\n",
      "search uid:05a17e58a7d0318c02ca957ea287c63a 3\n",
      "search uid:05a3e00d1bf81123eaa16d9140781814 4\n",
      "search uid:05a86ee2ef6ca329c2d7bd29a0bd43a2 5\n",
      "search uid:05aa7401f543aff4eaa9804faf94fe5d 6\n",
      "search uid:05abd155225287be6ccc9e851743c33d 7\n",
      "search uid:05ac93f1cea114840ec678882df58bde 8\n",
      "search uid:05ac976dd6c437b557aacc0f8bf95820 9\n",
      "search uid:05ad91adac4f36090687b821074a6839 10\n",
      "search uid:05b00857a652495ecd61ff287eefa0fa 11\n",
      "search uid:05b0ed6b6c5a3c7ec0ee133658afc455 12\n",
      "search uid:05ba03da99f9a8fd86ce5cedabb74eaa 13\n",
      "search uid:05ba689e3f3d89f4f1de80b156f09c51 14\n",
      "search uid:05bab1fcb0bef33fd6ab88f718d5d41d 15\n",
      "search uid:05bc20ee20f50b744c00d948da2ee82f 16\n",
      "search uid:05bc29c0517afb7cb63379e447646db2 17\n",
      "search uid:05bc52673524ae6b2342f8c00e815aa8 18\n",
      "search uid:05bd6785b6c3ca20728be79ed7e2fd73 19\n",
      "search uid:05be804ef16a4d1b3b442cc1668c15ca 20\n",
      "search uid:05bf76486b0c1eac3fab100d88678514 21\n",
      "search uid:05c1a7c2eecd8568015fcb7245aba5d8 22\n",
      "search uid:05c324e0a53b7b8b548163168e5c1763 23\n",
      "search uid:05ca5e5ab3bc016c4056bebfd971af90 24\n",
      "search uid:05cb634bc84a59d89c3747b9684cee56 25\n",
      "search uid:05cc9da72ceb5ad3e8fcbd5e3178f70c 26\n",
      "search uid:05ce6400d4ecf6b8c89cc281689da137 27\n",
      "search uid:05cfb9c7126bf9aa546686673c01eaee 28\n",
      "search uid:05d081c07b61499dd9647ebf883472e9 29\n",
      "search uid:05d219d1ce32acb7591dca2ca181bb51 30\n",
      "search uid:05d2b10375eaa12878f398267c2bedf9 31\n",
      "search uid:05d43f272ed3dfce12a22a4d4c509fcc 32\n",
      "search uid:05d79a718397917cfbe233968f069345 33\n",
      "search uid:05dc5aac901219181ccbd75f50afd0b4 34\n",
      "search uid:05df0f5c8252ae78d8bfd2e62290a7fa 35\n",
      "search uid:05e101976ec8f0d28ae4f25f5f5a4df4 36\n",
      "search uid:05e12cb9f7db55e84bf89006906e0f60 37\n",
      "search uid:05e18af6ed9b5a23b1642bf118e740d0 38\n",
      "search uid:05e4492aeefc260d3c8d0fbd70523c48 39\n",
      "search uid:05e60e17f6f7d473d2b0fc6c471f5af9 40\n",
      "search uid:05eab8ab56fc145464ae489d5e5ca9c1 41\n",
      "search uid:05ed33dbc866e3ce5d597e650bb99d65 42\n",
      "search uid:05edcddbfd2fcc147f7fb1bc09d3c0d9 43\n",
      "search uid:05ef9ec5b807b59c6788626408c44754 44\n",
      "search uid:05f0eee4768432862a7661085ed6533d 45\n",
      "search uid:05f57a02ea3698e84d45e10383e44d63 46\n",
      "search uid:05f974da06803245c215a2e13e059160 47\n",
      "search uid:05fec84bb78c23377204a76411be1be7 48\n",
      "search uid:05fff005c1d91f6ed477dbcd1c34111c 49\n",
      "search uid:0604bdbdc3d0c12ee5ed75f300f99f73 50\n",
      "search uid:0606698e2eb897452aa862bdac512726 51\n",
      "search uid:06079f6c6929fe184ecc805679066bed 52\n",
      "search uid:0609a0d54851bf22862d754ceda87b2b 53\n",
      "search uid:060b9e5107e8f29baed68962f6f8eaff 54\n",
      "search uid:060d776b251d79f434b75c69c4940462 55\n",
      "search uid:060f5a4f7e058bb2ff9c9de92cfad542 56\n",
      "search uid:061589a44fc0b6a40cf3e9807c510b6c 57\n",
      "search uid:0615c6631b18572c9b6387eb90d85ab5 58\n",
      "search uid:061a5a5ef25b09e39620d0408e7fec31 59\n",
      "search uid:061b887b096b9d808a474bff00473fc1 60\n",
      "search uid:061bd14b8a30dca2331a6c619739a5b3 61\n",
      "search uid:061c29516f8c179782a5546f47b47317 62\n",
      "search uid:061d1cbc09f676d9be499136844ecc16 63\n",
      "search uid:061dcf335c3c77727b8bdacb1eddc2f9 64\n",
      "search uid:061eff81086b93a607360775a2497998 65\n",
      "search uid:061f989b85ac194f5b4d845644d4310a 66\n",
      "search uid:062087b718dcf91fc9ccdb3164778d46 67\n",
      "search uid:0621633270b62ed5bd67cf932f3415f5 68\n",
      "search uid:0621b7682d67938d9b63c745fe2fd401 69\n",
      "search uid:0621eaff870b91d9c5177bb9a0534470 70\n",
      "search uid:06229bb279bedc152ba845da65da941b 71\n",
      "search uid:06240eed2b2c20c30c29c948d6ab5b73 72\n",
      "search uid:0625890a7a1cdef6336cffadd84f9e29 73\n",
      "search uid:0626b7ac922a88e8b6782ce9d3de2605 74\n",
      "search uid:062731665285bdb5c8e9e0a11a71c85e 75\n",
      "search uid:06275826c69fa270b3979f50368f4ecc 76\n",
      "search uid:06276dceec3540eeef29cc488c2a4b45 77\n",
      "search uid:06294a4f2333bedf4b33f9a0357cc4ce 78\n",
      "search uid:0629ef303d35298e48fb02d4424ab909 79\n",
      "search uid:062b899802ceff6a713702887d9d2e90 80\n",
      "search uid:0630665026540a028878b4cc753a356a 81\n",
      "search uid:0631e635b7a1eb8e3275ed767b2188cb 82\n",
      "search uid:063306849f9adab61d662f67f90a5d23 83\n",
      "search uid:063371083b2bb8cfaca892db2a703b2b 84\n",
      "search uid:06348c1b6f53b5434b57b786d50a0104 85\n",
      "search uid:0635ff2e769fc70d4f643dc639b4e9cc 86\n",
      "search uid:06371151752b567f1ca4de664faf3250 87\n",
      "search uid:06377961d878de50acea93b23219e7fe 88\n",
      "search uid:063a41bd09fbc1790b43263cc6107d2f 89\n",
      "search uid:063be5817b395ae8f439de921443179c 90\n",
      "search uid:063e88517736cab464595cf98676ede3 91\n",
      "search uid:063ee4a5343d064c2e49dd1cc9b45a6b 92\n",
      "search uid:064275777ee18e51251f78abfbd4e1ce 93\n",
      "search uid:0642a5738b33696fa17e69f3e46eaa96 94\n",
      "search uid:06437d2b81aa54e843967bbc8684fb2c 95\n",
      "search uid:064507c048c4185dcac8b4e9af81af5c 96\n",
      "search uid:0645345d36c461a0d2b53278cd926c99 97\n",
      "search uid:064978a78f30bf1637bcd794a6bc66b0 98\n",
      "search uid:064a46a12878658931471788f3eecff7 99\n",
      "search uid:064b5927535578d5b54b5f533a490819 100\n"
     ]
    }
   ],
   "source": [
    "uid_stat=pd.read_csv(\"train_uid_stat.csv\")\n",
    "uid_stat=uid_stat.set_index('u_id')\n",
    "uid = splitDataFrameIntoSmaller(uid_stat, chunkSize = 100)\n",
    "n=8\n",
    "while n<75:\n",
    "    df=uid[n].T\n",
    "    stat=df.to_dict('series')\n",
    "    n=n+1\n",
    "    search_all_uid(stat,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILES GENERATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "@runTime\n",
    "def predict_by_search(submission=True):\n",
    "\ttraindata,testdata = loadData()\n",
    "\t#concat all frames here\n",
    "\t\n",
    "\t\n",
    "\tub=pd.read_csv(\"train_best_pred.csv\")\n",
    "\tub=ub.set_index('u_id')\n",
    "\tdf=ub.T\n",
    "\tuid_best_pred=df.to_dict('series')\n",
    "\t#uid_best_pred = search_all_uid()\n",
    "\t#print (\"search done,now predict on traindata and testdata...\")\n",
    "\n",
    "\t#predict traindata with uid's best fp,cp,lp\n",
    "\tforward,comment,like = [],[],[]\n",
    "\tfor uid in traindata['u_id']:\n",
    "\t\tif uid in uid_best_pred:\n",
    "\t\t\tforward.append(int(uid_best_pred[uid][0]))\n",
    "\t\t\tcomment.append(int(uid_best_pred[uid][1]))\n",
    "\t\t\tlike.append(int(uid_best_pred[uid][2]))\n",
    "\t\telse:\n",
    "\t\t\tforward.append(0)\n",
    "\t\t\tcomment.append(0)\n",
    "\t\t\tlike.append(0)\n",
    "\t#score on the traindata\n",
    "\ttrain_real_pred = traindata[['forward_count','comment_count','like_count']]\n",
    "\ttrain_real_pred['fp'],train_real_pred['cp'],train_real_pred['lp'] = forward,comment,like\n",
    "\tprint (\"Score on the training set:{0:.2f}%\".format(precision(train_real_pred.values)*100))\n",
    "\tif submission:\n",
    "\t\ttest_pred = testdata[['u_id','m_id']]\n",
    "\t\tforward,comment,like = [],[],[]\n",
    "\t\tfor uid in testdata['u_id']:\n",
    "\t\t\tif uid in uid_best_pred:\n",
    "\t\t\t\tforward.append(int(uid_best_pred[uid][0]))\n",
    "\t\t\t\tcomment.append(int(uid_best_pred[uid][1]))\n",
    "\t\t\t\tlike.append(int(uid_best_pred[uid][2]))\n",
    "\t\t\telse:\n",
    "\t\t\t\tforward.append(0)\n",
    "\t\t\t\tcomment.append(0)\n",
    "\t\t\t\tlike.append(0)\n",
    "\t\ttest_pred['fp'],test_pred['cp'],test_pred['lp'] = forward,comment,like\n",
    "\t\t\n",
    "\t\t#generate submission file\n",
    "\t\tresult = []\n",
    "\t\tfilename = \"weibo_predict_search.txt\"\n",
    "\t\tfor _,row in test_pred.iterrows():\n",
    "\t\t\tresult.append(\"{0}\\t{1}\\t{2},{3},{4}\\n\".format(row[0],row[1],row[2],row[3],row[4]))\n",
    "\t\tf = open(filename,'w')\n",
    "\t\tf.writelines(result)\n",
    "\t\tf.close()\n",
    "\t\tprint ('generate submission file \"{}\"'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search uid:24b621c98f2594b698c0b1d60c9ae6db\n",
      "search uid:d38e9bed5d98110dc2489d0d1cac3c2a\n",
      "search uid:d80f3d3c5c1d658e82b837a4dd1af849\n",
      "search uid:da534fe87e7a52777bee5c30573ed5fd\n",
      "search uid:e06a22b7e065e559a1f0bf7841a85c51\n",
      "search uid:e44d81d630e4f382f657e72aa4b685da\n",
      "search uid:f349a67d1cd7c8683c5bbc5f8486e193\n",
      "search uid:f9828598f9664d4e347ef2048ce17734\n",
      "search uid:fa13974743d3fe6ff40d21b872325e9e\n",
      "search uid:fbe6c953632e1b3dda66cf6118b6ab12\n",
      "1\n",
      "Before loop\n",
      "\n",
      "search done,now predict on traindata and testdata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on the training set:55.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate submission file \"weibo_predict_search.txt\"\n",
      "predict_by_search run time: 72.50s\n"
     ]
    }
   ],
   "source": [
    "predict_by_search()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
