{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['copy', 'datetime']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%pylab inline\n",
    "import copy\n",
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import jieba\n",
    "import time\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.externals import joblib\n",
    "from nltk.corpus import stopwords as e_stopwords\n",
    "from datetime import datetime, timedelta\n",
    "import jieba\n",
    "import sys\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor for Statistical Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluation.ipynb\n",
      "importing Jupyter notebook from runTime.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from evaluation import precision\n",
    "from runTime import runTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data from document\n",
    "import pandas as pd\n",
    "df_pre=pd.read_csv(\"E:\\\\DMA_PRE\\\\PREPROCESSED.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37263"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_pre[0:8000]\n",
    "cv=df_pre[8001:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat=pd.read_csv(\"E:\\\\DMA_PRE\\\\train_uid_stat.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37263, 13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>forward_min</th>\n",
       "      <th>forward_max</th>\n",
       "      <th>forward_median</th>\n",
       "      <th>forward_mean</th>\n",
       "      <th>comment_min</th>\n",
       "      <th>comment_max</th>\n",
       "      <th>comment_median</th>\n",
       "      <th>comment_mean</th>\n",
       "      <th>like_min</th>\n",
       "      <th>like_max</th>\n",
       "      <th>like_median</th>\n",
       "      <th>like_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000127c6126e2b0019f255ed21ac1cb7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001565a5edece1669577e2ace9a6a3d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00033a6513b86b2705de9ffa9d37ffb6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004fe2742507420eaa73e119dc83ac5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c663a24a2f91f4ba156fcd4f8b9f2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               u_id  forward_min  forward_max  forward_median  \\\n",
       "0  000127c6126e2b0019f255ed21ac1cb7            0            1               0   \n",
       "1  0001565a5edece1669577e2ace9a6a3d            0            0               0   \n",
       "2  00033a6513b86b2705de9ffa9d37ffb6            0            0               0   \n",
       "3  0004fe2742507420eaa73e119dc83ac5            0            6               0   \n",
       "4  000c663a24a2f91f4ba156fcd4f8b9f2            0            1               0   \n",
       "\n",
       "   forward_mean  comment_min  comment_max  comment_median  comment_mean  \\\n",
       "0             0            0            0               0             0   \n",
       "1             0            0            1               0             0   \n",
       "2             0            0            0               0             0   \n",
       "3             0            0            1               0             0   \n",
       "4             0            0            7               0             0   \n",
       "\n",
       "   like_min  like_max  like_median  like_mean  \n",
       "0         0         0            0          0  \n",
       "1         0         0            0          0  \n",
       "2         0         1            0          0  \n",
       "3         0         1            0          0  \n",
       "4         0         6            0          0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all1=pd.read_csv('E:\\\\5th-Sem\\\\DMA Project\\\\Model Evaluation\\\\weibo_train1_cp.csv')\n",
    "train_all2=pd.read_csv('E:\\\\5th-Sem\\\\DMA Project\\\\Model Evaluation\\\\weibo_train2_cp.csv')\n",
    "frames=[train_all1,train_all2]\n",
    "train_all=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1229618"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(train_all, df_stat, how='left', on=['u_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"E:\\\\5th-Sem\\\\DMA Project\\\\Project\\\\weibo_train1_cpts.csv\")\n",
    "df2=pd.read_csv(\"E:\\\\5th-Sem\\\\DMA Project\\\\Project\\\\weibo_train2_cpts.csv\")\n",
    "frames=[df1,df2]\n",
    "train_all=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_all[[\"content_media_count\",\"content_#_count\",\"content_length\",\"content_emoji_count\",\"forward_median\",\"comment_median\",\"like_median\"]]\n",
    "y=train_all[['forward_count', 'comment_count', 'like_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "## Spliting of training dataset into 70% training data and 30% testing data randomly\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 (Predicting all 3 values together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "x = features_train\n",
    "y = labels_train\n",
    "x1 = features_test\n",
    "y1 = labels_test\n",
    "\n",
    "\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=30, random_state=0,n_estimators=100)\n",
    "regr.fit(x, y)\n",
    "y11_predict = regr.predict(x1)\n",
    "y11_predict=y11_predict.round()\n",
    "y11_predict=(np.maximum(y11_predict,0.))\n",
    "#print(r2_score(y1, y11_predict) ) #Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"E:\\\\weibo_predict_result.csv\",y11_predict,delimiter=',',header=\"forward_count,comment_count,like_count\",comments=\"\")\n",
    "result=pd.read_csv(\"E:\\\\weibo_predict_result.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on the training set:30.04%\n"
     ]
    }
   ],
   "source": [
    "train_real_pred = labels_test\n",
    "forward=result['forward_count'].values\n",
    "comment=result['comment_count'].values\n",
    "like=result['like_count'].values\n",
    "train_real_pred['fp'],train_real_pred['cp'],train_real_pred['lp'] = forward,comment,like\n",
    "print (\"Score on the training set:{0:.2f}%\".format(precision(train_real_pred.values)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u_id</th>\n",
       "      <td>d38e9bed5d98110dc2489d0d1cac3c2a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_id</th>\n",
       "      <td>7d45833d9865727a88b960b0603c19f6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content</th>\n",
       "      <td>丽江旅游(sz002033)#股票##炒股##财经##理财##投资#推荐包赢股，盈利对半分成...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>2015-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>17:41:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_media_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_#_count</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_@_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_?_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_!_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_length</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_emoji_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sec</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward_min</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward_max</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward_median</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward_mean</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_min</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_max</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_median</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_mean</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like_min</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like_max</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like_median</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like_mean</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     0\n",
       "u_id                                  d38e9bed5d98110dc2489d0d1cac3c2a\n",
       "m_id                                  7d45833d9865727a88b960b0603c19f6\n",
       "forward_count                                                        0\n",
       "comment_count                                                        0\n",
       "like_count                                                           0\n",
       "content              丽江旅游(sz002033)#股票##炒股##财经##理财##投资#推荐包赢股，盈利对半分成...\n",
       "date                                                        2015-02-23\n",
       "time                                                          17:41:29\n",
       "content_media_count                                                  0\n",
       "content_#_count                                                     10\n",
       "content_@_count                                                      0\n",
       "content_?_count                                                      0\n",
       "content_!_count                                                      0\n",
       "content_length                                                      62\n",
       "content_emoji_count                                                  0\n",
       "hour                                                                17\n",
       "min                                                                 41\n",
       "sec                                                                 29\n",
       "forward_min                                                          0\n",
       "forward_max                                                        114\n",
       "forward_median                                                       0\n",
       "forward_mean                                                         1\n",
       "comment_min                                                          0\n",
       "comment_max                                                         48\n",
       "comment_median                                                       0\n",
       "comment_mean                                                         0\n",
       "like_min                                                             0\n",
       "like_max                                                             5\n",
       "like_median                                                          0\n",
       "like_mean                                                            0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - Constructing 3 individual models and concatinating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X=train_all[[\"forward_median\",\"forward_mean\",\"forward_min\",\"content_media_count\",\"content_emoji_count\"]]\n",
    "y=train_all['forward_count']\n",
    "from sklearn import cross_validation\n",
    "## Spliting of training dataset into 70% training data and 30% testing data randomly\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "x = features_train\n",
    "y = labels_train\n",
    "x1 = features_test\n",
    "y1 = labels_test\n",
    "\n",
    "\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=30, random_state=0,n_estimators=100)\n",
    "regr.fit(x, y)\n",
    "y11_predict = regr.predict(x1)\n",
    "#print(r2_score(y1, y11_predict) ) #Random forest regressor\n",
    "np.savetxt(\"E:\\\\weibo_predict_result1.csv\",y11_predict,delimiter=',',header=\"forward_count\",comments=\"\")\n",
    "result1=pd.read_csv(\"E:\\\\weibo_predict_result1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_all[[\"comment_median\",\"comment_mean\",\"comment_min\",\"content_media_count\",\"content_emoji_count\"]]\n",
    "y=train_all['comment_count']\n",
    "from sklearn import cross_validation\n",
    "## Spliting of training dataset into 70% training data and 30% testing data randomly\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "x = features_train\n",
    "y = labels_train\n",
    "x1 = features_test\n",
    "y2 = labels_test\n",
    "\n",
    "\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=30, random_state=0,n_estimators=100)\n",
    "regr.fit(x, y)\n",
    "y11_predict = regr.predict(x1)\n",
    "#print(r2_score(y1, y11_predict) ) #Random forest regressor\n",
    "np.savetxt(\"E:\\\\weibo_predict_result2.csv\",y11_predict,delimiter=',',header=\"comment_count\",comments=\"\")\n",
    "result2=pd.read_csv(\"E:\\\\weibo_predict_result2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_all[[\"like_median\",\"like_mean\",\"like_min\",\"content_media_count\",\"content_emoji_count\"]]\n",
    "y=train_all['like_count']\n",
    "from sklearn import cross_validation\n",
    "## Spliting of training dataset into 70% training data and 30% testing data randomly\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "x = features_train\n",
    "y = labels_train\n",
    "x1 = features_test\n",
    "y3 = labels_test\n",
    "\n",
    "\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=30, random_state=0,n_estimators=100)\n",
    "regr.fit(x, y)\n",
    "y11_predict = regr.predict(x1)\n",
    "#print(r2_score(y1, y11_predict) ) #Random forest regressor\n",
    "np.savetxt(\"E:\\\\weibo_predict_result3.csv\",y11_predict,delimiter=',',header=\"like_count\",comments=\"\")\n",
    "result3=pd.read_csv(\"E:\\\\weibo_predict_result3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on the training set:12.1019%\n"
     ]
    }
   ],
   "source": [
    "train_real_pred = pd.concat([y1,y2,y3],axis=1)\n",
    "train_real_pred['fp']=result1['forward_count']\n",
    "train_real_pred['cp']=result2['comment_count']\n",
    "train_real_pred['lp']=result3['like_count']\n",
    "train_real_pred=train_real_pred.round()\n",
    "print (\"Score on the training set:{0:.4f}%\".format(precision(train_real_pred.values)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
