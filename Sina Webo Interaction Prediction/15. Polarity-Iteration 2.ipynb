{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluation.ipynb\n",
      "importing Jupyter notebook from runTime.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from evaluation import precision\n",
    "from runTime import runTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------Polarity as a factor--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences with positive meaning have positive polarity and negative meaning ones have negative polarity and neutral ones have zero as polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpol=pd.read_csv(\"C:/Users/user/Downloads/weibo_polarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>u_id</th>\n",
       "      <th>m_id</th>\n",
       "      <th>forward_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>content_media_count</th>\n",
       "      <th>...</th>\n",
       "      <th>like_median</th>\n",
       "      <th>like_mean</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>content_spchar</th>\n",
       "      <th>non_emoji_content</th>\n",
       "      <th>en_content</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>url_rem</th>\n",
       "      <th>contentwurl</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>d38e9bed5d98110dc2489d0d1cac3c2a</td>\n",
       "      <td>7d45833d9865727a88b960b0603c19f6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>丽江旅游(sz002033)#股票##炒股##财经##理财##投资#推荐包赢股，盈利对半分成...</td>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>17:41:29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['('  ')'  '#'  '#'  '#'  '#'  '#'  '#'  '#'  ...</td>\n",
       "      <td>丽江旅游(sz002033)#股票##炒股##财经##理财##投资#推荐包赢股，盈利对半分成...</td>\n",
       "      <td>Lijiang Tourism (sz002033) # ## stock stocks F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lijiang Tourism (sz002033) # ## stock stocks F...</td>\n",
       "      <td>-0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>d38e9bed5d98110dc2489d0d1cac3c2a</td>\n",
       "      <td>00755196c77936bf44656ada98291c59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>想开了就是幸福，想不开就是痛苦…http://t.cn/RLqzYa1</td>\n",
       "      <td>2015-07-13</td>\n",
       "      <td>19:24:50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['#'  '#'  '，'  '。'  '@'  '，'  '！'  '，'  '╮'  ...</td>\n",
       "      <td>#丁辰灵的红包#挣钱是一种能力，抢红包拼的是技术。我抢到了丁辰灵 和@阚洪岩 一起发出的现金...</td>\n",
       "      <td>Chen Ling Ding # # red envelopes to make money...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chen Ling Ding # # red envelopes to make money...</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>d38e9bed5d98110dc2489d0d1cac3c2a</td>\n",
       "      <td>4fedf3888b1e16592f0e0bdc8b393845</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300419浩丰科技#股票##股神##股市##炒股##财经##理财##投资# 股票庄家，要求...</td>\n",
       "      <td>2015-03-14</td>\n",
       "      <td>21:22:57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>['。'  '。'  '。'  '~'  '，']</td>\n",
       "      <td>淘宝网这些傻逼。。。气的劳资有火没地儿发~尼玛，你们都瞎了</td>\n",
       "      <td>Taobao these sucker. . . Industrial gas fire n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Taobao these sucker. . . Industrial gas fire n...</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>d38e9bed5d98110dc2489d0d1cac3c2a</td>\n",
       "      <td>91be0b8612265aae32725cd4fa80b222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>女性被人占便宜从来不生气，是什么心态？http://t.cn/R2n2pRz</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>16:25:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>['，'  '['  ']']</td>\n",
       "      <td>看点不能说的，你们都懂[笑cry]</td>\n",
       "      <td>Aspect can not say, you know everything [laugh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aspect can not say, you know everything [laugh...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>d38e9bed5d98110dc2489d0d1cac3c2a</td>\n",
       "      <td>bd2af99ecf1298f5539f0ddfcdd3ed64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>网宿科技(sz300017)#股票##炒股##财经##理财##投资#推荐包赢股，盈利对半分成...</td>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>17:35:31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>111多张</td>\n",
       "      <td>Over 111 Zhang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Over 111 Zhang</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>d38e9bed5d98110dc2489d0d1cac3c2a</td>\n",
       "      <td>182078c5a409834f2128b3c9c2c289c3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>中国平安(sh601318)#股票##炒股##财经##理财##投资#推荐包赢股，盈利对半分成...</td>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>17:30:13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>['！'  '！'  '！'  '@'  ':'  '/'  '/'  '.'  '/']</td>\n",
       "      <td>有生之年！我最喜欢的up主跟我的三体勾搭到一起了！幸福感爆棚！ @黑桐谷歌  http://...</td>\n",
       "      <td>Lifetime! My favorite up with the main body ho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lifetime! My favorite up with the main body ho...</td>\n",
       "      <td>0.354167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>d38e9bed5d98110dc2489d0d1cac3c2a</td>\n",
       "      <td>2c9697e5d6f1d9d479540173c4c374cb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300013新宁物流#股票##股神##股市##炒股##财经##理财##投资# 股票庄家，要求...</td>\n",
       "      <td>2015-03-14</td>\n",
       "      <td>21:24:36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>['？'  ':'  '/'  '/'  '.'  '/'  '（'  '@'  '）']</td>\n",
       "      <td>论优衣库试衣间隔音效果好坏？ http://t.cn/RL5aSzp（分享自 @知乎）</td>\n",
       "      <td>On Uniqlo dressing room sound insulation is go...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On Uniqlo dressing room sound insulation is go...</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>d38e9bed5d98110dc2489d0d1cac3c2a</td>\n",
       "      <td>0ce5d103d7712b398ee2e81f83f49751</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>今年最流行的空气感刘海，你剪了？（多图）http://t.cn/R2mdwd7</td>\n",
       "      <td>2015-06-19</td>\n",
       "      <td>22:31:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>['，'  '。'  '，'  '，'  '。']</td>\n",
       "      <td>如此平凡的日常一幕，还能够再积累多少呢。 终有一天，当我们到了看着这张照片能感受到一阵怀念的...</td>\n",
       "      <td>So ordinary everyday scene, but also how much ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So ordinary everyday scene, but also how much ...</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>d38e9bed5d98110dc2489d0d1cac3c2a</td>\n",
       "      <td>a651facd0523d2a85a0717b83928c6c8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>002326永太科技#股票##股神##股市##炒股##财经##理财##投资#推荐包赢股，盈利...</td>\n",
       "      <td>2015-03-05</td>\n",
       "      <td>16:36:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>['#'  '#'  '，'  '，'  '！'  '@'  '！'  '，'  '~'  ...</td>\n",
       "      <td>#罗永浩的红包#二十三，糖瓜儿粘，抢个红包乐翻天！我抢到了罗永浩 和@_王先森就是我 一起发...</td>\n",
       "      <td>Overheating of red # # xxiii, Tanggua children...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overheating of red # # xxiii, Tanggua children...</td>\n",
       "      <td>0.110937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>d38e9bed5d98110dc2489d0d1cac3c2a</td>\n",
       "      <td>3e1895f6017e0214f7392013552ac96a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>603636南威软件#股票##股神##股市##炒股##财经##理财##投资##新股##大盘#...</td>\n",
       "      <td>2015-03-23</td>\n",
       "      <td>12:30:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>['！'  '，'  '，'  '？'  '：'  ':'  '/'  '/'  '.'  ...</td>\n",
       "      <td>有好东西分享给你！闪记笔记记事，最好用的中文待办软件，还等什么？快去下载： http://t...</td>\n",
       "      <td>There are good things to share with you! Flash...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There are good things to share with you! Flash...</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              u_id  \\\n",
       "0           0  d38e9bed5d98110dc2489d0d1cac3c2a   \n",
       "1           1  d38e9bed5d98110dc2489d0d1cac3c2a   \n",
       "2           2  d38e9bed5d98110dc2489d0d1cac3c2a   \n",
       "3           3  d38e9bed5d98110dc2489d0d1cac3c2a   \n",
       "4           4  d38e9bed5d98110dc2489d0d1cac3c2a   \n",
       "5           5  d38e9bed5d98110dc2489d0d1cac3c2a   \n",
       "6           6  d38e9bed5d98110dc2489d0d1cac3c2a   \n",
       "7           7  d38e9bed5d98110dc2489d0d1cac3c2a   \n",
       "8           8  d38e9bed5d98110dc2489d0d1cac3c2a   \n",
       "9           9  d38e9bed5d98110dc2489d0d1cac3c2a   \n",
       "\n",
       "                               m_id  forward_count  comment_count  like_count  \\\n",
       "0  7d45833d9865727a88b960b0603c19f6              0              0           0   \n",
       "1  00755196c77936bf44656ada98291c59              0              0           0   \n",
       "2  4fedf3888b1e16592f0e0bdc8b393845              0              0           0   \n",
       "3  91be0b8612265aae32725cd4fa80b222              0              0           0   \n",
       "4  bd2af99ecf1298f5539f0ddfcdd3ed64              0              0           0   \n",
       "5  182078c5a409834f2128b3c9c2c289c3              0              0           0   \n",
       "6  2c9697e5d6f1d9d479540173c4c374cb              0              0           0   \n",
       "7  0ce5d103d7712b398ee2e81f83f49751              0              0           0   \n",
       "8  a651facd0523d2a85a0717b83928c6c8              0              0           0   \n",
       "9  3e1895f6017e0214f7392013552ac96a              0              0           0   \n",
       "\n",
       "                                             content        date      time  \\\n",
       "0  丽江旅游(sz002033)#股票##炒股##财经##理财##投资#推荐包赢股，盈利对半分成...  2015-02-23  17:41:29   \n",
       "1                想开了就是幸福，想不开就是痛苦…http://t.cn/RLqzYa1  2015-07-13  19:24:50   \n",
       "2  300419浩丰科技#股票##股神##股市##炒股##财经##理财##投资# 股票庄家，要求...  2015-03-14  21:22:57   \n",
       "3             女性被人占便宜从来不生气，是什么心态？http://t.cn/R2n2pRz  2015-06-18  16:25:36   \n",
       "4  网宿科技(sz300017)#股票##炒股##财经##理财##投资#推荐包赢股，盈利对半分成...  2015-02-23  17:35:31   \n",
       "5  中国平安(sh601318)#股票##炒股##财经##理财##投资#推荐包赢股，盈利对半分成...  2015-02-23  17:30:13   \n",
       "6  300013新宁物流#股票##股神##股市##炒股##财经##理财##投资# 股票庄家，要求...  2015-03-14  21:24:36   \n",
       "7            今年最流行的空气感刘海，你剪了？（多图）http://t.cn/R2mdwd7  2015-06-19  22:31:51   \n",
       "8  002326永太科技#股票##股神##股市##炒股##财经##理财##投资#推荐包赢股，盈利...  2015-03-05  16:36:16   \n",
       "9  603636南威软件#股票##股神##股市##炒股##财经##理财##投资##新股##大盘#...  2015-03-23  12:30:09   \n",
       "\n",
       "   content_media_count    ...     like_median  like_mean  Unnamed: 0.1  \\\n",
       "0                  0.0    ...               0          0             0   \n",
       "1                  1.0    ...               0          0             1   \n",
       "2                  0.0    ...               0          0             2   \n",
       "3                  1.0    ...               0          0             3   \n",
       "4                  0.0    ...               0          0             4   \n",
       "5                  0.0    ...               0          0             5   \n",
       "6                  0.0    ...               0          0             6   \n",
       "7                  1.0    ...               0          0             7   \n",
       "8                  0.0    ...               0          0             8   \n",
       "9                  0.0    ...               0          0             9   \n",
       "\n",
       "                                      content_spchar  \\\n",
       "0  ['('  ')'  '#'  '#'  '#'  '#'  '#'  '#'  '#'  ...   \n",
       "1  ['#'  '#'  '，'  '。'  '@'  '，'  '！'  '，'  '╮'  ...   \n",
       "2                          ['。'  '。'  '。'  '~'  '，']   \n",
       "3                                    ['，'  '['  ']']   \n",
       "4                                                 []   \n",
       "5      ['！'  '！'  '！'  '@'  ':'  '/'  '/'  '.'  '/']   \n",
       "6      ['？'  ':'  '/'  '/'  '.'  '/'  '（'  '@'  '）']   \n",
       "7                          ['，'  '。'  '，'  '，'  '。']   \n",
       "8  ['#'  '#'  '，'  '，'  '！'  '@'  '！'  '，'  '~'  ...   \n",
       "9  ['！'  '，'  '，'  '？'  '：'  ':'  '/'  '/'  '.'  ...   \n",
       "\n",
       "                                   non_emoji_content  \\\n",
       "0  丽江旅游(sz002033)#股票##炒股##财经##理财##投资#推荐包赢股，盈利对半分成...   \n",
       "1  #丁辰灵的红包#挣钱是一种能力，抢红包拼的是技术。我抢到了丁辰灵 和@阚洪岩 一起发出的现金...   \n",
       "2                      淘宝网这些傻逼。。。气的劳资有火没地儿发~尼玛，你们都瞎了   \n",
       "3                                  看点不能说的，你们都懂[笑cry]   \n",
       "4                                              111多张   \n",
       "5  有生之年！我最喜欢的up主跟我的三体勾搭到一起了！幸福感爆棚！ @黑桐谷歌  http://...   \n",
       "6        论优衣库试衣间隔音效果好坏？ http://t.cn/RL5aSzp（分享自 @知乎）   \n",
       "7  如此平凡的日常一幕，还能够再积累多少呢。 终有一天，当我们到了看着这张照片能感受到一阵怀念的...   \n",
       "8  #罗永浩的红包#二十三，糖瓜儿粘，抢个红包乐翻天！我抢到了罗永浩 和@_王先森就是我 一起发...   \n",
       "9  有好东西分享给你！闪记笔记记事，最好用的中文待办软件，还等什么？快去下载： http://t...   \n",
       "\n",
       "                                          en_content  Unnamed: 1  url_rem  \\\n",
       "0  Lijiang Tourism (sz002033) # ## stock stocks F...         NaN      NaN   \n",
       "1  Chen Ling Ding # # red envelopes to make money...         NaN      NaN   \n",
       "2  Taobao these sucker. . . Industrial gas fire n...         NaN      NaN   \n",
       "3  Aspect can not say, you know everything [laugh...         NaN      NaN   \n",
       "4                                    Over 111 Zhang          NaN      NaN   \n",
       "5  Lifetime! My favorite up with the main body ho...         NaN      NaN   \n",
       "6  On Uniqlo dressing room sound insulation is go...         NaN      NaN   \n",
       "7  So ordinary everyday scene, but also how much ...         NaN      NaN   \n",
       "8  Overheating of red # # xxiii, Tanggua children...         NaN      NaN   \n",
       "9  There are good things to share with you! Flash...         NaN      NaN   \n",
       "\n",
       "                                         contentwurl  polarity  \n",
       "0  Lijiang Tourism (sz002033) # ## stock stocks F... -0.166667  \n",
       "1  Chen Ling Ding # # red envelopes to make money...  0.175000  \n",
       "2  Taobao these sucker. . . Industrial gas fire n... -0.400000  \n",
       "3  Aspect can not say, you know everything [laugh...  0.000000  \n",
       "4                                    Over 111 Zhang   0.000000  \n",
       "5  Lifetime! My favorite up with the main body ho...  0.354167  \n",
       "6  On Uniqlo dressing room sound insulation is go...  0.133333  \n",
       "7  So ordinary everyday scene, but also how much ... -0.083333  \n",
       "8  Overheating of red # # xxiii, Tanggua children...  0.110937  \n",
       "9  There are good things to share with you! Flash...  0.625000  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpol.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'u_id', 'm_id', 'forward_count', 'comment_count',\n",
       "       'like_count', 'content', 'date', 'time', 'content_media_count',\n",
       "       'content_#_count', 'content_@_count', 'content_?_count',\n",
       "       'content_!_count', 'content_length', 'content_emoji_count', 'hour',\n",
       "       'min', 'sec', 'forward_min', 'forward_max', 'forward_median',\n",
       "       'forward_mean', 'comment_min', 'comment_max', 'comment_median',\n",
       "       'comment_mean', 'like_min', 'like_max', 'like_median', 'like_mean',\n",
       "       'Unnamed: 0.1', 'content_spchar', 'non_emoji_content', 'en_content',\n",
       "       'Unnamed: 1', 'url_rem', 'contentwurl', 'polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpol.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpol['date']=pd.to_datetime(dfpol['date'],errors='coerce')\n",
    "train_month=[g for n, g in dfpol.groupby(pd.Grouper(key='date',freq='M'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_month[0]=pd.read_csv(\"C:/Users/user/Downloads/weibo_train_feb_cpts10000.csv\")\n",
    "train_month[1]=pd.read_csv(\"C:/Users/user/Downloads/weibo_train_march_cpts10000.csv\")\n",
    "train_month[2]=pd.read_csv(\"C:/Users/user/Downloads/weibo_train_april_cpts10000.csv\")\n",
    "train_month[3]=pd.read_csv(\"C:/Users/user/Downloads/weibo_train_may_cpts10000.csv\")\n",
    "train_month[4]=pd.read_csv(\"C:/Users/user/Downloads/weibo_train_june_cpts10000.csv\")\n",
    "train_month[5]=pd.read_csv(\"C:/Users/user/Downloads/weibo_train_july_cpts10000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames1=[train_month[0],train_month[1],train_month[2],train_month[3],train_month[4]]\n",
    "train=pd.concat(frames1)\n",
    "predict=train_month[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7: (Factors: Media, Length, Emoji, Median,Polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_train1=train[[\"content_media_count\",\"content_length\",\"forward_median\",\"comment_median\",\"like_median\",\"polarity\"]]\n",
    "Y_train1=train[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "X_test1=predict[[\"content_media_count\",\"content_length\",\"forward_median\",\"comment_median\",\"like_median\",\"polarity\"]]\n",
    "Y_test1=predict[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "X_train1.fillna(X_train1.max(),inplace=True)\n",
    "X_test1.fillna(X_test1.max(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1=linear_model.LinearRegression()\n",
    "model1=lm1.fit(X_train1,Y_train1)\n",
    "pred1=lm1.predict(X_test1)\n",
    "pred1=pred1.round()\n",
    "pred1=(np.maximum(pred1,0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.60345081e-01   6.74510609e-03  -9.03871388e+00  -5.69877934e+00\n",
      "    1.46618263e+01  -3.00702607e-01]\n",
      " [ -4.52559256e-01   2.88854313e-04  -2.58935392e+00   3.20973326e-01\n",
      "    2.56664104e+00   1.78063868e-01]\n",
      " [ -1.70607807e-01  -1.73336140e-03  -2.49319057e+00  -7.66383744e-01\n",
      "    3.84877692e+00   1.34944972e-01]]\n",
      "[ 0.09961692  0.27754213  0.23556883]\n"
     ]
    }
   ],
   "source": [
    "print(model1.coef_)\n",
    "print(model1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"C:/Users/user/Downloads/weibo_predict_result51.csv\",pred1,delimiter=',',header=\"forward_count,comment_count,like_count\",comments=\"\")\n",
    "result1=pd.read_csv(\"C:/Users/user/Downloads/weibo_predict_result51.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.2745912995\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(Y_test1,result1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:35.39%\n"
     ]
    }
   ],
   "source": [
    "train_real_pred=Y_test1\n",
    "train_real_pred['fp']=result1['forward_count']\n",
    "train_real_pred['cp']=result1['comment_count']\n",
    "train_real_pred['lp']=result1['like_count']\n",
    "print(\"Score:{0:.2f}%\".format(precision(train_real_pred.values)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Result with Polarity as factor are satisfactory considering the data used for train. This might prove to be a good factor for whole dataset prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 8: (Factors: Media, Length,Median,Polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_train1=train[[\"content_media_count\",\"content_length\",\"forward_mean\",\"comment_mean\",\"like_mean\",\"polarity\"]]\n",
    "Y_train1=train[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "X_test1=predict[[\"content_media_count\",\"content_length\",\"forward_mean\",\"comment_mean\",\"like_mean\",\"polarity\"]]\n",
    "Y_test1=predict[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "X_train1.fillna(X_train1.max(),inplace=True)\n",
    "X_test1.fillna(X_test1.max(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1=linear_model.LinearRegression()\n",
    "model1=lm1.fit(X_train1,Y_train1)\n",
    "pred1=lm1.predict(X_test1)\n",
    "pred1=pred1.round()\n",
    "pred1=(np.maximum(pred1,0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.84153944e-01   1.16499672e-02   1.23769730e+00   5.03985664e-01\n",
      "   -5.30125012e-01   2.40824642e-01]\n",
      " [ -4.34205066e-01   2.65588900e-03   4.65693627e-02   8.21537197e-01\n",
      "   -4.63148333e-03   8.38895495e-02]\n",
      " [ -1.07997853e-01  -6.08462330e-04   1.24279057e-01  -2.25635181e-02\n",
      "    7.47271891e-01   1.46482193e-01]]\n",
      "[-1.685958    0.04881615  0.00796132]\n"
     ]
    }
   ],
   "source": [
    "print(model1.coef_)\n",
    "print(model1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"C:/Users/user/Downloads/weibo_predict_result51.csv\",pred1,delimiter=',',header=\"forward_count,comment_count,like_count\",comments=\"\")\n",
    "result1=pd.read_csv(\"C:/Users/user/Downloads/weibo_predict_result51.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.0421169299\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(Y_test1,result1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:34.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_real_pred=Y_test1\n",
    "train_real_pred['fp']=result1['forward_count']\n",
    "train_real_pred['cp']=result1['comment_count']\n",
    "train_real_pred['lp']=result1['like_count']\n",
    "print(\"Score:{0:.2f}%\".format(precision(train_real_pred.values)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 9: (Factors: Media, Length, Emoji, Median,Mean,Polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_train1=train[[\"content_media_count\",\"content_length\",\"forward_mean\",\"forward_median\",\"comment_mean\",\"comment_median\",\"like_mean\",\"like_median\",\"polarity\"]]\n",
    "Y_train1=train[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "X_test1=predict[[\"content_media_count\",\"content_length\",\"forward_mean\",\"forward_median\",\"comment_mean\",\"comment_median\",\"like_mean\",\"like_median\",\"polarity\"]]\n",
    "Y_test1=predict[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "X_train1.fillna(X_train1.max(),inplace=True)\n",
    "X_test1.fillna(X_test1.max(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1=linear_model.LinearRegression()\n",
    "model1=lm1.fit(X_train1,Y_train1)\n",
    "pred1=lm1.predict(X_test1)\n",
    "pred1=pred1.round()\n",
    "pred1=(np.maximum(pred1,0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.24002976e-01   1.39830856e-02   1.77218462e+00   5.28953775e+00\n",
      "    5.32073405e-01   2.72797599e+00   9.08606236e-02  -8.60889360e+00\n",
      "    4.57317719e-01]\n",
      " [ -3.94970258e-01   2.85864515e-03   1.34655712e-01   5.14556038e-01\n",
      "    7.61232739e-01   4.96108919e-01   2.61640134e-02  -1.03251918e+00\n",
      "    1.30303697e-01]\n",
      " [ -2.52656284e-01  -1.69108114e-03  -1.95657316e-01  -2.51251894e+00\n",
      "    9.14012006e-02  -1.71242671e+00   4.71094851e-01   4.48754073e+00\n",
      "   -7.29299942e-04]]\n",
      "[-2.47378947 -0.06752787  0.45657126]\n"
     ]
    }
   ],
   "source": [
    "print(model1.coef_)\n",
    "print(model1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"C:/Users/user/Downloads/weibo_predict_result51.csv\",pred1,delimiter=',',header=\"forward_count,comment_count,like_count\",comments=\"\")\n",
    "result1=pd.read_csv(\"C:/Users/user/Downloads/weibo_predict_result51.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.9952895539\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(Y_test1,result1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:34.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_real_pred=Y_test1\n",
    "train_real_pred['fp']=result1['forward_count']\n",
    "train_real_pred['cp']=result1['comment_count']\n",
    "train_real_pred['lp']=result1['like_count']\n",
    "print(\"Score:{0:.2f}%\".format(precision(train_real_pred.values)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model10: (Factors: Media, Length, Emoji, Median,Polarity) with OLS\n",
    "\n",
    "### OLS is a type of linear least sqaures methods for estimating parameters in a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_train1=train[[\"content_media_count\",\"content_length\",\"forward_median\",\"comment_median\",\"like_median\",\"polarity\"]]\n",
    "Y_train1=train[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "X_test1=predict[[\"content_media_count\",\"content_length\",\"forward_median\",\"comment_median\",\"like_median\",\"polarity\"]]\n",
    "Y_test1=predict[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "X_train1.fillna(X_train1.max(),inplace=True)\n",
    "X_test1.fillna(X_test1.max(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=sm.OLS(Y_train1,X_train1).fit()\n",
    "pred1=model1.predict(X_test1)\n",
    "pred1=pred1.round()\n",
    "pred1=(np.maximum(pred1,0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"C:/Users/user/Downloads/weibo_predict_result52.csv\",pred1,delimiter=',',header=\"forward_count,comment_count,like_count\",comments=\"\")\n",
    "result1=pd.read_csv(\"C:/Users/user/Downloads/weibo_predict_result52.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:35.39%\n"
     ]
    }
   ],
   "source": [
    "train_real_pred=Y_test1\n",
    "train_real_pred['fp']=result1['forward_count']\n",
    "train_real_pred['cp']=result1['comment_count']\n",
    "train_real_pred['lp']=result1['like_count']\n",
    "print(\"Score:{0:.2f}%\".format(precision(train_real_pred.values)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model11: (Factors: Media, Length, Emoji, Median,Polarity) with Ridge regression\n",
    "\n",
    "### Ridge regression is used to prevent multicollinearity among variables by shrinking the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_train1=train[[\"content_media_count\",\"content_length\",\"forward_median\",\"comment_median\",\"like_median\",\"polarity\"]]\n",
    "Y_train1=train[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "X_test1=predict[[\"content_media_count\",\"content_length\",\"forward_median\",\"comment_median\",\"like_median\",\"polarity\"]]\n",
    "Y_test1=predict[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "X_train1.fillna(X_train1.max(),inplace=True)\n",
    "X_test1.fillna(X_test1.max(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1=linear_model.Ridge(alpha=3)\n",
    "model1=lm1.fit(X_train1,Y_train1)\n",
    "pred1=lm1.predict(X_test1)\n",
    "pred1=pred1.round()\n",
    "pred1=(np.maximum(pred1,0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.86510208e-01   6.41054941e-03  -8.34912342e+00  -5.36638332e+00\n",
      "    1.39393510e+01  -2.63639792e-01]\n",
      " [ -4.56306722e-01   1.98158232e-04  -2.45402009e+00   3.77596491e-01\n",
      "    2.43239453e+00   1.84454477e-01]\n",
      " [ -1.76866329e-01  -1.82770299e-03  -2.31640230e+00  -6.84262708e-01\n",
      "    3.66606306e+00   1.43628492e-01]]\n",
      "[ 0.12872141  0.28577674  0.2444117 ]\n"
     ]
    }
   ],
   "source": [
    "print(model1.coef_)\n",
    "print(model1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"C:/Users/user/Downloads/weibo_predict_result53.csv\",pred1,delimiter=',',header=\"forward_count,comment_count,like_count\",comments=\"\")\n",
    "result1=pd.read_csv(\"C:/Users/user/Downloads/weibo_predict_result53.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:35.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_real_pred=Y_test1\n",
    "train_real_pred['fp']=result1['forward_count']\n",
    "train_real_pred['cp']=result1['comment_count']\n",
    "train_real_pred['lp']=result1['like_count']\n",
    "print(\"Score:{0:.2f}%\".format(precision(train_real_pred.values)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 12: (Factors: Media, Length, Emoji, Median,Polarity) with Lasso regression\n",
    "\n",
    "### Lasso regression does automatic feature selection that means if some features are correlated then lasso will pick only one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_train1=train[[\"content_media_count\",\"content_length\",\"forward_median\",\"comment_median\",\"like_median\",\"polarity\"]]\n",
    "Y_train1=train[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "X_test1=predict[[\"content_media_count\",\"content_length\",\"forward_median\",\"comment_median\",\"like_median\",\"polarity\"]]\n",
    "Y_test1=predict[[\"forward_count\",\"comment_count\",\"like_count\"]]\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "X_train1.fillna(X_train1.max(),inplace=True)\n",
    "X_test1.fillna(X_test1.max(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1=Lasso(alpha=0.01)\n",
    "model1=lm1.fit(X_train1,Y_train1)\n",
    "pred1=lm1.predict(X_test1)\n",
    "pred1=pred1.round()\n",
    "pred1=(np.maximum(pred1,0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.93885876e-01   5.30762986e-03  -7.01981756e+00  -4.71960564e+00\n",
      "    1.25490926e+01  -8.17241037e-02]\n",
      " [ -3.98749279e-01  -1.15532108e-03  -1.29700987e+00   7.65902250e-01\n",
      "    1.36959059e+00   8.67988313e-02]\n",
      " [ -1.33179860e-01  -2.99999206e-03  -8.19004244e-01  -0.00000000e+00\n",
      "    2.14881763e+00   4.81255664e-02]]\n",
      "[ 0.09786835  0.4897481   0.43776902]\n"
     ]
    }
   ],
   "source": [
    "print(model1.coef_)\n",
    "print(model1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"C:/Users/user/Downloads/weibo_predict_result54.csv\",pred1,delimiter=',',header=\"forward_count,comment_count,like_count\",comments=\"\")\n",
    "result1=pd.read_csv(\"C:/Users/user/Downloads/weibo_predict_result54.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:35.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_real_pred=Y_test1\n",
    "train_real_pred['fp']=result1['forward_count']\n",
    "train_real_pred['cp']=result1['comment_count']\n",
    "train_real_pred['lp']=result1['like_count']\n",
    "print(\"Score:{0:.2f}%\".format(precision(train_real_pred.values)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
