{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluation.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import import_ipynb\n",
    "from evaluation import precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_month1=pd.read_csv(\"E:\\5th Sem\\DMA Project\\Model Evaluation\\weibo_train_feb_cpts.csv\")\n",
    "train_month2=pd.read_csv(\"E:\\5th Sem\\DMA Project\\Model Evaluation\\weibo_train_march_cpts.csv\")\n",
    "train_month3=pd.read_csv(\"E:\\5th Sem\\DMA Project\\Model Evaluation\\weibo_train_april_cpts.csv\")\n",
    "train_month4=pd.read_csv(\"E:\\5th Sem\\DMA Project\\Model Evaluation\\weibo_train_may_cpts.csv\")\n",
    "train_month5=pd.read_csv(\"E:\\5th Sem\\DMA Project\\Model Evaluation\\weibo_train_june_cpts.csv\")\n",
    "train_month6=pd.read_csv(\"E:\\5th Sem\\DMA Project\\Model Evaluation\\weibo_train_july_cpts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames1=[train_month1,train_month2,train_month3,train_month4,train_month5]\n",
    "train=pd.concat(frames1)\n",
    "predict=train_month6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044681, 5) (1044681, 1)\n",
      "(184937, 5) (184937, 1)\n",
      "(1044681, 5) (1044681, 1)\n",
      "(184937, 5) (184937, 1)\n",
      "(1044681, 5) (1044681, 1)\n",
      "(184937, 5) (184937, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train1=train[[\"forward_median\",\"forward_mean\",\"forward_min\",\"content_media_count\",\"content_emoji_count\"]]\n",
    "Y_train1=train[[\"forward_count\"]]\n",
    "X_test1=predict[[\"forward_median\",\"forward_mean\",\"forward_min\",\"content_media_count\",\"content_emoji_count\"]]\n",
    "Y_test1=predict[[\"forward_count\"]]\n",
    "\n",
    "X_train2=train[[\"comment_median\",\"comment_mean\",\"comment_min\",\"content_media_count\",\"content_emoji_count\"]]\n",
    "Y_train2=train[[\"comment_count\"]]\n",
    "X_test2=predict[[\"comment_median\",\"comment_mean\",\"comment_min\",\"content_media_count\",\"content_emoji_count\"]]\n",
    "Y_test2=predict[[\"comment_count\"]]\n",
    "\n",
    "X_train3=train[[\"like_median\",\"like_mean\",\"like_min\",\"content_media_count\",\"content_emoji_count\"]]\n",
    "Y_train3=train[[\"like_count\"]]\n",
    "X_test3=predict[[\"like_median\",\"like_mean\",\"like_min\",\"content_media_count\",\"content_emoji_count\"]]\n",
    "Y_test3=predict[[\"like_count\"]]\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "X_train1.fillna(X_train1.max(),inplace=True)\n",
    "X_test1.fillna(X_test1.max(),inplace=True)\n",
    "X_train2.fillna(X_train2.max(),inplace=True)\n",
    "X_test2.fillna(X_test2.max(),inplace=True)\n",
    "X_train3.fillna(X_train3.max(),inplace=True)\n",
    "X_test3.fillna(X_test3.max(),inplace=True)\n",
    "\n",
    "print(X_train1.shape,Y_train1.shape)\n",
    "print(X_test1.shape,Y_test1.shape)\n",
    "\n",
    "print(X_train2.shape,Y_train2.shape)\n",
    "print(X_test2.shape,Y_test2.shape)\n",
    "\n",
    "print(X_train3.shape,Y_train3.shape)\n",
    "print(X_test3.shape,Y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          forward_count   R-squared:                       0.155\n",
      "Model:                            OLS   Adj. R-squared:                  0.155\n",
      "Method:                 Least Squares   F-statistic:                 3.837e+04\n",
      "Date:                Thu, 08 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        18:51:04   Log-Likelihood:            -6.0303e+06\n",
      "No. Observations:             1044681   AIC:                         1.206e+07\n",
      "Df Residuals:                 1044676   BIC:                         1.206e+07\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "forward_median          0.4510      0.011     41.482      0.000       0.430       0.472\n",
      "forward_mean            0.8472      0.008    104.955      0.000       0.831       0.863\n",
      "forward_min            -0.2918      0.224     -1.301      0.193      -0.731       0.148\n",
      "content_media_count     0.1469      0.089      1.651      0.099      -0.028       0.321\n",
      "content_emoji_count    -0.0135      0.329     -0.041      0.967      -0.658       0.631\n",
      "===============================================================================\n",
      "Omnibus:                  5350284.603   Durbin-Watson:                    2.008\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   394619723036624.188\n",
      "Skew:                         234.725   Prob(JB):                          0.00\n",
      "Kurtosis:                   95216.359   Cond. No.                          152.\n",
      "===============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          comment_count   R-squared:                       0.141\n",
      "Model:                            OLS   Adj. R-squared:                  0.141\n",
      "Method:                 Least Squares   F-statistic:                 3.437e+04\n",
      "Date:                Thu, 08 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        18:51:05   Log-Likelihood:            -4.5502e+06\n",
      "No. Observations:             1044681   AIC:                         9.100e+06\n",
      "Df Residuals:                 1044676   BIC:                         9.101e+06\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "comment_median         -0.2502      0.017    -14.783      0.000      -0.283      -0.217\n",
      "comment_mean            1.1808      0.010    119.894      0.000       1.161       1.200\n",
      "comment_min             0.0641      0.160      0.401      0.689      -0.249       0.378\n",
      "content_media_count    -0.1673      0.022     -7.733      0.000      -0.210      -0.125\n",
      "content_emoji_count     0.0507      0.080      0.635      0.525      -0.106       0.207\n",
      "===============================================================================\n",
      "Omnibus:                  5213202.872   Durbin-Watson:                    1.956\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   199884674609233.969\n",
      "Skew:                         214.327   Prob(JB):                          0.00\n",
      "Kurtosis:                   67766.344   Cond. No.                          73.3\n",
      "===============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             like_count   R-squared:                       0.370\n",
      "Model:                            OLS   Adj. R-squared:                  0.370\n",
      "Method:                 Least Squares   F-statistic:                 1.229e+05\n",
      "Date:                Thu, 08 Nov 2018   Prob (F-statistic):               0.00\n",
      "Time:                        18:51:06   Log-Likelihood:            -5.1616e+06\n",
      "No. Observations:             1044681   AIC:                         1.032e+07\n",
      "Df Residuals:                 1044676   BIC:                         1.032e+07\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "like_median             0.1165      0.014      8.225      0.000       0.089       0.144\n",
      "like_mean               0.9511      0.012     78.935      0.000       0.927       0.975\n",
      "like_min               -0.1539      0.252     -0.610      0.542      -0.649       0.341\n",
      "content_media_count    -0.2240      0.039     -5.791      0.000      -0.300      -0.148\n",
      "content_emoji_count    -0.0588      0.143     -0.411      0.681      -0.340       0.222\n",
      "==============================================================================\n",
      "Omnibus:                  4825971.004   Durbin-Watson:                   1.943\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   88805152128512.828\n",
      "Skew:                         163.871   Prob(JB):                         0.00\n",
      "Kurtosis:                   45170.018   Cond. No.                         247.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model1=sm.OLS(Y_train1,X_train1).fit()\n",
    "pred1=model1.predict(X_test1)\n",
    "pred1=pred1.round()\n",
    "pred1=(np.maximum(pred1,0.))\n",
    "print(model1.summary())\n",
    "\n",
    "model2=sm.OLS(Y_train2,X_train2).fit()\n",
    "pred2=model2.predict(X_test2)\n",
    "pred2=pred2.round()\n",
    "pred2=(np.maximum(pred2,0.))\n",
    "print(model2.summary())\n",
    "\n",
    "model3=sm.OLS(Y_train3,X_train3).fit()\n",
    "pred3=model3.predict(X_test3)\n",
    "pred3=pred3.round()\n",
    "pred3=(np.maximum(pred3,0.))\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3.0\n",
      "1     3.0\n",
      "2     3.0\n",
      "3    13.0\n",
      "4    12.0\n",
      "dtype: float64\n",
      "0    4.0\n",
      "1    4.0\n",
      "2    4.0\n",
      "3    4.0\n",
      "4    3.0\n",
      "dtype: float64\n",
      "0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "3    6.0\n",
      "4    4.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pred1[0:5])\n",
    "\n",
    "print(pred2[0:5])\n",
    "\n",
    "print(pred3[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"G://DMA_PROJECT//weibo_predict_resulto1.csv\",pred1,delimiter=',',header=\"forward_count\",comments=\"\")\n",
    "result1=pd.read_csv(\"G://DMA_PROJECT//weibo_predict_resulto1.csv\")\n",
    "np.savetxt(\"G://DMA_PROJECT//weibo_predict_resulto2.csv\",pred2,delimiter=',',header=\"comment_count\",comments=\"\")\n",
    "result2=pd.read_csv(\"G://DMA_PROJECT//weibo_predict_resulto2.csv\")\n",
    "np.savetxt(\"G://DMA_PROJECT//weibo_predict_resulto3.csv\",pred3,delimiter=',',header=\"like_count\",comments=\"\")\n",
    "result3=pd.read_csv(\"G://DMA_PROJECT//weibo_predict_resulto3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on the training set:27.86%\n"
     ]
    }
   ],
   "source": [
    "train_real_pred = pd.concat([Y_test1,Y_test2,Y_test3],axis=1)\n",
    "train_real_pred['fp']=result1['forward_count']\n",
    "train_real_pred['cp']=result2['comment_count']\n",
    "train_real_pred['lp']=result3['like_count']\n",
    "train_real_pred=train_real_pred.round()\n",
    "print (\"Score on the training set:{0:.2f}%\".format(precision(train_real_pred.values)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
