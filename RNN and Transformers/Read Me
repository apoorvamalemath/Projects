Putting together implementations of Recurrent Neural Networks, Transformer (encoder and decoder), and their applications to text classification, image classification, and text generation (machine translation). Especially for Transformer, you will get good understandings about foundations for very state-of-the-art models that you likely to see in tech news articles nowadays, like GPT-3, CLIP, or VisionTransformer
